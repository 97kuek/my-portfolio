---
title: OpenCVを用いた動体検知の方法
description: 'PythonとOpenCVを使った背景差分法による動体検知の仕組みと実装手順を解説します。'
pubDate: '2025-10-02'
tags: ['Python', 'OpenCV', '動体検知', '背景差分法']
---

こんにちは！今回は、自動ドアや防犯カメラなど、身近なシステムで利用されている**動体検知**の仕組みを**初心者にもわかりやすく解説**していきたいと思います。

また、動体検知のシミュレーションコードを作成したので、実際に動体検知を体感してみましょう！

[Motion-Detection-App](https://github.com/97kuek/Motion-Detection-App)

このリポジトリでは、Python と OpenCV を用いて、動体検知の仕組みとしては古典的な**背景差分法**を採用しています。

## はじめに：動体検知とは？

動体検知は、画像や映像の中から**動いているもの**を見つけ出す技術です。防犯カメラ、自動ドア、交通量調査など、私たちの身の回りの多くのシステムで利用されています。最もシンプルな問いは、「前の瞬間と比べて、何が変わったか？」です。この問いに答えるのが、今回の主役である**背景差分法**です。

## 背景差分法

背景差分法は、その名の通り「現在の映像」から「背景だけの映像」を**引き算（差分計算）**することで、前景、つまり動いている物体を抽出する手法です。

-   `現在のフレーム - 背景フレーム = 動いている物体`

非常にシンプルですが、**いくつかの課題**があります。例えば、照明の微妙な変化や木の葉の揺れなど、本来は「動き」として検知したくないものまで拾ってしまう可能性があります。また、「背景」そのものが時間とともに変化することもあります（例：駐車していた車が走り去る）。

これらの課題を克服するため、本プログラムでは次のようなステップを踏んでいきます。

## 1. 映像の入力と前処理

まず、OpenCVを使ってビデオソース（Webカメラなど）からフレームを1枚ずつ読み込みます。しかし、カラー映像のままでは情報量が多すぎて処理が大変です。

1.  **グレースケール化**: 色情報をなくし、画像の明るさ（輝度）情報だけにします。これにより、計算コストが大幅に削減されます。
2.  **平滑化（ぼかし）**: `GaussianBlur` を使って画像に軽いぼかしをかけます。これは、カメラセンサーが拾ってしまう微細なノイズ（高周波ノイズ）を減らし、後の差分計算がより安定して行えるようにするための重要な下準備です。

## 2. 背景モデルの構築

**「背景」をどう定義するか**は、この手法の肝です。単純に「最初の1フレームを背景とする」だけでは、その後に背景が変化した場合に対応できません。

そこで、**移動加重平均（Running Average）** という考え方を使います。`cv2.accumulateWeighted` 関数がこれにあたります。

```python
cv2.accumulateWeighted(gray, avg, LEARN_RATE)
```

これは、過去の背景モデル `avg` と現在のフレーム `gray` を、`LEARN_RATE` という「学習率」に基づいてブレンドし、背景モデルを少しずつ更新していく処理です。

-   **学習率が高い**: 最新のフレームを重視します。背景の変化に素早く追従できますが、一時的に止まった物体を背景と誤認識しやすくなります。
-   **学習率が低い**: 過去の背景を重視します。ゆっくりとした変化に強いですが、急な背景変化への対応が遅れます。

この処理を繰り返すことで、「平均的な背景」を表現する、賢い背景モデル `avg` が育っていきます。

## 3. 差分の計算

背景モデルが準備できたら、現在のフレーム（グレースケール）と背景モデルとの差分を計算します。`cv2.absdiff` 関数は、2つの画像の各ピクセル値の差の絶対値を取ります。これにより、変化があった部分だけが白く浮かび上がる「差分画像」が生成されます。

## 4. 2値化とノイズ除去

差分画像は、まだ濃淡のあるグレースケール画像です。これを「動きがあった部分」と「なかった部分」の白黒2値画像に変換する必要があります。

1.  **大津の2値化 (`THRESH_OTSU`)**: `cv2.threshold` にこのオプションを指定すると、プログラムが画像の輝度分布を分析し、最適なしきい値を自動で決定してくれます。これにより、照明環境がある程度変わっても安定して2値化できます。

2.  **形態学的処理（ノイズ除去）**: 2値化画像には、まだ小さな白点ノイズ（検出しなくてよい微小な変化）や、検出したい物体の内部にある黒い穴などが含まれていることがあります。
    *   **オープニング (`MORPH_OPEN`)**: 小さな白点ノイズ（ゴマ塩ノイズ）を除去します。
    *   **膨張 (`dilate`)**: 物体の領域を少し広げる処理です。これにより、物体内部の小さな穴を埋めることができます。

これらの処理を経て、動いている物体の領域が、よりクリーンな白い塊として抽出されます。

## 5. 輪郭の検出

クリーンになった2値画像から、`cv2.findContours` を使って白い塊の輪郭を見つけ出します。輪郭は、動いている各オブジェクトに対応します。

## 6. フィルタリングとイベント発生

検出されたすべての輪郭が、意味のある「動き」とは限りません。非常に小さな輪郭はノイズである可能性が高いため、`cv2.contourArea` で面積を計算し、一定のしきい値 (`area_min`) 未満のものは無視します。

さらに、「人が通り過ぎる」といった一連の動きを、1つの「イベント」としてカウントするための仕組みを導入しています。

-   `hit_streak`: 「動きあり」が何フレーム連続したかをカウントします。これが一定数 (`persist_frames`) を超えると、**イベント開始**とみなします。
-   `quiet_streak`: 逆に「動きなし」が何フレーム連続したかをカウントします。イベント中にこれが一定数 (`quiet_frames`) を超えると、**イベント終了**とみなします。

このステートマシンにより、蝶がひらひらと舞うような断続的な動きを、バラバラに何度もカウントしてしまうのを防ぎ、より意味のある単位でイベントを捉えることができます。

## おわりに

本プロジェクトの動体検知は、以下のステップを組み合わせることで実現されています。

`前処理 → 背景モデル更新 → 差分計算 → 2値化 → ノイズ除去 → 輪郭検出 → フィルタリング → イベント判定`

一見複雑に見えますが、一つ一つの処理は非常に論理的です。この背景差分法は、より高度な機械学習ベースの手法（YOLOなど）への入門としても、非常に優れた題材です。ぜひ `config.json` のパラメータを色々調整して、その挙動の変化を観察してみてください！
